{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Zt6fuJBzmNN"
   },
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rq-6yROFN3xQ"
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGVeSPfk5GLs"
   },
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "def car_inspector(path_to_file):\n",
    "    img = cv2.imread(path_to_file)\n",
    "    outputs = predictor(img)\n",
    "    v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imwrite(path_to_file, out.get_image()[:, :, ::-1])\n",
    "\n",
    "    bound_area = (outputs[\"instances\"].pred_boxes.area().tolist())\n",
    "    bound_classes = (outputs[\"instances\"].pred_classes.tolist())\n",
    "    num_cars = sum([bound_class==2 for bound_class in bound_classes])\n",
    "    little_car = True\n",
    "    if num_cars > 0:\n",
    "\n",
    "        biggest_area = sorted(bound_area)[-1]\n",
    "        big_area = biggest_area*0.5 # to take bounding box with area 50% and bigger of the biggest area detected\n",
    "\n",
    "        detected_car = []\n",
    "        for j in range(len(bound_classes)):\n",
    "            if str(bound_classes[j]) == '2':\n",
    "                if bound_area[j] > big_area:\n",
    "                    little_car = False\n",
    "                    index_area = (j, bound_area[j])\n",
    "                    detected_car.append(index_area)\n",
    "                \n",
    "        if little_car == False:\n",
    "            biggest_car = max(detected_car, key=lambda index_area:index_area[1])\n",
    "            print(biggest_car)\n",
    "            mask = outputs[\"instances\"].pred_boxes[biggest_car[0]]\n",
    "            mask = mask.tensor.tolist()\n",
    "\n",
    "            x = int(float(mask[0][0]))\n",
    "            y = int(float(mask[0][1]))\n",
    "            w = int(float(mask[0][2]))\n",
    "            h = int(float(mask[0][3]))\n",
    "\n",
    "            croped_car = Image.open(path_to_file)\n",
    "            croped_car = croped_car.crop((x, y, w, h)).save(path_to_file)\n",
    "        else: \n",
    "            print('на фото '+ path_to_file + 'нет автомобиля подходящего размера')\n",
    "    else:\n",
    "        print('на фото '+ path_to_file + 'нет автомобиля!'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-seC2Wvzq1r"
   },
   "outputs": [],
   "source": [
    "#директории на локальном компьютере, где проводилась предобработка датасета.\n",
    "dir_img = 'D:/car_dataset/_learn/'\n",
    "dir_train = dir_img + 'train/'\n",
    "dir_test = dir_img + 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04ePCUfwOfrc"
   },
   "outputs": [],
   "source": [
    "#Обрабатываем каждое изображение Детектроном2 и вырезаем автомобиль по баундинг-боксу\n",
    "for car_model in os.listdir(dir_train):\n",
    "    for filename in os.listdir(dir_train + car_model + '/'):\n",
    "        path_to_file = dir_train + car_model +'/'+filename\n",
    "        biggest_car_in_bounds(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "KByhCPt727ZE",
    "outputId": "17896455-1f9f-4050-f54c-6c3ec660a188"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 89/89 [12:01<00:00,  8.11s/it]\n"
     ]
    }
   ],
   "source": [
    "#Приводим все фотки к квадратному виду без искажения изображений. Затем ресайзим до размера 331x331 (с этим разрешением\n",
    "#работает используемая нами нейросеть NasNetLarge)\n",
    "\n",
    "for car_model in tqdm(os.listdir(dir_train)):\n",
    "    for filename in os.listdir(dir_train + car_model + '/'):\n",
    "        img  = Image.open(dir_train + car_model +'/'+filename)\n",
    "        max_size = max(img.size)\n",
    "        \n",
    "        new_size = (max_size, max_size)\n",
    "        new_im = Image.new(\"RGB\", new_size)\n",
    "        new_im.paste(img, (round((new_size[0]-img.size[0])/2),round((new_size[1]-img.size[1])/2)))\n",
    "        new_im = new_im.resize((331,331))\n",
    "        new_im.save(dir_train+car_model+'/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8GoBub3HogU",
    "outputId": "dcf93e7e-eeea-4ace-dcfe-559a93ff2325"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 89/89 [00:01<00:00, 45.25it/s]\n"
     ]
    }
   ],
   "source": [
    "#Переносим ~30% картинок по каждому классу в валидационную папку\n",
    "\n",
    "for class_dir in tqdm(os.listdir(dir_train)):\n",
    "    f = os.listdir(dir_train + class_dir)\n",
    "    count_files = len(f)\n",
    "    i = 0\n",
    "    os.mkdir(dir_train + class_dir)\n",
    "    for filename in os.listdir(dir_train + class_dir):\n",
    "        \n",
    "        os.rename(dir_train + class_dir + '/' + filename, dir_test + class_dir+'/'+ filename)\n",
    "        i += 1\n",
    "        if i >= round(count_files*0.3):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zw05EQlM9L7C"
   },
   "outputs": [],
   "source": [
    "#Начало работы на Google Colab. Переносим наш датасет в локальное окружение сервера.\n",
    "!mkdir '/content/Cars/'\n",
    "!cp \"/content/drive/MyDrive/datasets/Cars/car/crop.zip\" '/content/Cars/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAP5_k1-H0xz"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/Cars/crop.zip\" -d \"/content/Cars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SoGwxuXgI8M4",
    "outputId": "c8e2c92a-9fac-4b29-8746-857e1a0637b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8emaE0OUHogU"
   },
   "outputs": [],
   "source": [
    "base_dir= '/content/Cars/crop'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bMCb2Z0PHogV",
    "outputId": "0eaed9ae-d448-4eaa-b396-40eb456669a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n",
      "343613440/343610240 [==============================] - 7s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Загружаем модель NASNetLarge, присоединяем к ней новую \"голову\", и получаем нашу модель, которую нужно дообучить.\n",
    "\n",
    "model_NASNetLarge = keras.applications.NASNetLarge(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(331,331,3))\n",
    "\n",
    "x = model_NASNetLarge.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "          \n",
    "output = layers.Dense(89, activation='softmax')(x)\n",
    "\n",
    "model_with_NASNetLarge=keras.Model(inputs=model_NASNetLarge.inputs, outputs=output)\n",
    "#model_with_NASNetLarge.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3FJtidlHogV"
   },
   "outputs": [],
   "source": [
    "#Замораживаем все слои, кроме последнего. Последний будем учить. \n",
    "for layer in model_with_NASNetLarge.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbiBE91JHogW"
   },
   "outputs": [],
   "source": [
    "# Компиляция модели. В качестве метрик задаём accuracy и Top4_Accuracy. Последняя метрика для нас важна, посльку telegram-bot будет выходить\n",
    "# 4 первых предсказания модели автомобиля.\n",
    "\n",
    "model_with_NASNetLarge.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy',keras.metrics.TopKCategoricalAccuracy(\n",
    "    k=4, name=\"top_4_accuracy\", dtype=None)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWGWFNceHogW",
    "outputId": "729bac13-3883-4e2b-9d2e-c32204e13725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13186 images belonging to 89 classes.\n",
      "Found 5653 images belonging to 89 classes.\n"
     ]
    }
   ],
   "source": [
    "#Создание генераторов изображений, которые будут брать файлы из нужных папок и скармливать обучающейся модели.\n",
    "#Делаем небольшую аугументацию, чтобы предотвратить достаточно быстрое переобучение модели. \n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "        rotation_range=15, \n",
    "        brightness_range=(0.9, 1.1),\n",
    "        channel_shift_range=50,\n",
    "        horizontal_flip=True,\n",
    "        )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(331, 331),  \n",
    "        batch_size=64,\n",
    "        class_mode='categorical'\n",
    "        )\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(331, 331),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3Onbh3yHogW"
   },
   "outputs": [],
   "source": [
    "#отдельно создаём объект для колбэка, который будет сохранять модель при улучшении val_top_4_accuracy по результатам каждой эпохи.\n",
    "#важно объявить объект отдельно, а не в fit_generator, иначе объект будет создаваться каждый раз при запуске обучения, из-за чего\n",
    "# информация о лучшем val_top_4_accuracy обнулится. \n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath = '/content/drive/MyDrive/models/car1/', monitor='val_top_4_accuracy', verbose=1, save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TD_0YSBcHogX",
    "outputId": "81d618c1-7010-4e22-d8e8-54ee1944c607"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 117s 117s/step - loss: 2.5257 - accuracy: 0.7031 - top_4_accuracy: 0.8750 - val_loss: 3.0228 - val_accuracy: 0.6085 - val_top_4_accuracy: 0.8599\n"
     ]
    }
   ],
   "source": [
    "#Запускаем обучение\n",
    "\n",
    "history = model_with_NASNetLarge.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=206, \n",
    "      callbacks = checkpoint,\n",
    "      epochs=20,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=88, \n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhFSQWcZLLga",
    "outputId": "a3caed01-0069-4189-d5f7-62b52b85da6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/models/car/assets\n"
     ]
    }
   ],
   "source": [
    "model_with_NASNetLarge.save('/content/drive/MyDrive/models/car1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6jFu_q-twdo"
   },
   "outputs": [],
   "source": [
    "model_with_NASNetLarge = keras.models.load_model('/content/drive/MyDrive/models/car')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "car_classification_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
